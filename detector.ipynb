{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/maxkucher/Library/Python/3.9/lib/python/site-packages/urllib3/__init__.py:35: NotOpenSSLWarning: urllib3 v2 only supports OpenSSL 1.1.1+, currently the 'ssl' module is compiled with 'LibreSSL 2.8.3'. See: https://github.com/urllib3/urllib3/issues/3020\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "from ultralytics import YOLO\n",
    "import pickle \n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = \"/Users/maxkucher/pytorch/howitzer-detector/analyzer_nn.pickle\"\n",
    "\n",
    "with open(file_path, \"rb\") as file:\n",
    "    analyzer_model = pickle.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_28\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_169 (Dense)           (None, 6)                 30        \n",
      "                                                                 \n",
      " dense_170 (Dense)           (None, 8)                 56        \n",
      "                                                                 \n",
      " dense_171 (Dense)           (None, 5)                 45        \n",
      "                                                                 \n",
      " dense_172 (Dense)           (None, 7)                 42        \n",
      "                                                                 \n",
      " dense_173 (Dense)           (None, 4)                 32        \n",
      "                                                                 \n",
      " dense_174 (Dense)           (None, 3)                 15        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 220 (880.00 Byte)\n",
      "Trainable params: 220 (880.00 Byte)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "analyzer_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 (no detections), 429.6ms\n",
      "Speed: 7.1ms preprocess, 429.6ms inference, 3.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 379.3ms\n",
      "Speed: 1.7ms preprocess, 379.3ms inference, 0.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 526.9ms\n",
      "Speed: 1.4ms preprocess, 526.9ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 320.9ms\n",
      "Speed: 2.1ms preprocess, 320.9ms inference, 0.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 392.5ms\n",
      "Speed: 1.5ms preprocess, 392.5ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 342.7ms\n",
      "Speed: 8.3ms preprocess, 342.7ms inference, 0.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 380.2ms\n",
      "Speed: 1.5ms preprocess, 380.2ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 401.5ms\n",
      "Speed: 1.7ms preprocess, 401.5ms inference, 0.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 404.8ms\n",
      "Speed: 1.8ms preprocess, 404.8ms inference, 0.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 348.9ms\n",
      "Speed: 2.1ms preprocess, 348.9ms inference, 0.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 356.5ms\n",
      "Speed: 1.8ms preprocess, 356.5ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 465.4ms\n",
      "Speed: 16.1ms preprocess, 465.4ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 370.8ms\n",
      "Speed: 1.7ms preprocess, 370.8ms inference, 0.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 347.7ms\n",
      "Speed: 1.7ms preprocess, 347.7ms inference, 0.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 347.2ms\n",
      "Speed: 1.9ms preprocess, 347.2ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 361.9ms\n",
      "Speed: 1.2ms preprocess, 361.9ms inference, 0.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 354.7ms\n",
      "Speed: 2.8ms preprocess, 354.7ms inference, 0.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 384.8ms\n",
      "Speed: 19.7ms preprocess, 384.8ms inference, 0.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 372.8ms\n",
      "Speed: 6.2ms preprocess, 372.8ms inference, 0.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 353.0ms\n",
      "Speed: 1.1ms preprocess, 353.0ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 423.7ms\n",
      "Speed: 1.5ms preprocess, 423.7ms inference, 0.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 381.8ms\n",
      "Speed: 3.0ms preprocess, 381.8ms inference, 0.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 359.4ms\n",
      "Speed: 1.1ms preprocess, 359.4ms inference, 0.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 354.7ms\n",
      "Speed: 1.5ms preprocess, 354.7ms inference, 0.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 334.7ms\n",
      "Speed: 1.5ms preprocess, 334.7ms inference, 0.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 348.1ms\n",
      "Speed: 1.1ms preprocess, 348.1ms inference, 0.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 353.1ms\n",
      "Speed: 2.3ms preprocess, 353.1ms inference, 0.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 366.6ms\n",
      "Speed: 1.2ms preprocess, 366.6ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 377.4ms\n",
      "Speed: 1.6ms preprocess, 377.4ms inference, 0.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 343.7ms\n",
      "Speed: 1.6ms preprocess, 343.7ms inference, 0.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 391.3ms\n",
      "Speed: 1.3ms preprocess, 391.3ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 352.0ms\n",
      "Speed: 1.5ms preprocess, 352.0ms inference, 0.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 446.5ms\n",
      "Speed: 1.2ms preprocess, 446.5ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 359.8ms\n",
      "Speed: 1.3ms preprocess, 359.8ms inference, 0.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 342.3ms\n",
      "Speed: 3.2ms preprocess, 342.3ms inference, 0.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 355.3ms\n",
      "Speed: 1.7ms preprocess, 355.3ms inference, 0.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 338.3ms\n",
      "Speed: 5.7ms preprocess, 338.3ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 331.8ms\n",
      "Speed: 1.2ms preprocess, 331.8ms inference, 0.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 365.1ms\n",
      "Speed: 1.5ms preprocess, 365.1ms inference, 0.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 329.5ms\n",
      "Speed: 4.7ms preprocess, 329.5ms inference, 0.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 356.8ms\n",
      "Speed: 1.3ms preprocess, 356.8ms inference, 0.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 374.6ms\n",
      "Speed: 4.4ms preprocess, 374.6ms inference, 0.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 341.1ms\n",
      "Speed: 1.1ms preprocess, 341.1ms inference, 0.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 341.9ms\n",
      "Speed: 1.4ms preprocess, 341.9ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 391.4ms\n",
      "Speed: 1.4ms preprocess, 391.4ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 368.8ms\n",
      "Speed: 7.6ms preprocess, 368.8ms inference, 0.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 330.1ms\n",
      "Speed: 1.3ms preprocess, 330.1ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 363.9ms\n",
      "Speed: 1.5ms preprocess, 363.9ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 345.2ms\n",
      "Speed: 1.7ms preprocess, 345.2ms inference, 0.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 361.3ms\n",
      "Speed: 1.2ms preprocess, 361.3ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 363.4ms\n",
      "Speed: 1.3ms preprocess, 363.4ms inference, 0.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 374.9ms\n",
      "Speed: 1.6ms preprocess, 374.9ms inference, 0.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 367.1ms\n",
      "Speed: 1.3ms preprocess, 367.1ms inference, 0.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 412.3ms\n",
      "Speed: 1.5ms preprocess, 412.3ms inference, 0.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 350.6ms\n",
      "Speed: 1.5ms preprocess, 350.6ms inference, 0.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 351.0ms\n",
      "Speed: 1.2ms preprocess, 351.0ms inference, 0.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 381.8ms\n",
      "Speed: 1.5ms preprocess, 381.8ms inference, 0.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 359.1ms\n",
      "Speed: 1.4ms preprocess, 359.1ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 398.8ms\n",
      "Speed: 1.3ms preprocess, 398.8ms inference, 0.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 373.3ms\n",
      "Speed: 1.4ms preprocess, 373.3ms inference, 0.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 351.3ms\n",
      "Speed: 1.6ms preprocess, 351.3ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 359.9ms\n",
      "Speed: 1.4ms preprocess, 359.9ms inference, 0.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 346.3ms\n",
      "Speed: 1.8ms preprocess, 346.3ms inference, 0.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 355.0ms\n",
      "Speed: 1.7ms preprocess, 355.0ms inference, 0.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 354.8ms\n",
      "Speed: 1.6ms preprocess, 354.8ms inference, 0.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 344.0ms\n",
      "Speed: 1.2ms preprocess, 344.0ms inference, 0.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 375.0ms\n",
      "Speed: 1.7ms preprocess, 375.0ms inference, 0.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 361.2ms\n",
      "Speed: 1.9ms preprocess, 361.2ms inference, 0.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 328.0ms\n",
      "Speed: 1.2ms preprocess, 328.0ms inference, 0.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 335.6ms\n",
      "Speed: 1.8ms preprocess, 335.6ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 372.4ms\n",
      "Speed: 1.4ms preprocess, 372.4ms inference, 0.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 342.6ms\n",
      "Speed: 1.6ms preprocess, 342.6ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 376.3ms\n",
      "Speed: 1.6ms preprocess, 376.3ms inference, 0.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 340.3ms\n",
      "Speed: 1.8ms preprocess, 340.3ms inference, 0.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 342.9ms\n",
      "Speed: 1.3ms preprocess, 342.9ms inference, 0.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 362.0ms\n",
      "Speed: 16.0ms preprocess, 362.0ms inference, 0.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 392.8ms\n",
      "Speed: 6.0ms preprocess, 392.8ms inference, 0.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 368.4ms\n",
      "Speed: 1.5ms preprocess, 368.4ms inference, 0.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 349.2ms\n",
      "Speed: 1.5ms preprocess, 349.2ms inference, 0.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 365.4ms\n",
      "Speed: 1.4ms preprocess, 365.4ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 368.2ms\n",
      "Speed: 1.1ms preprocess, 368.2ms inference, 0.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 332.7ms\n",
      "Speed: 1.5ms preprocess, 332.7ms inference, 0.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 356.0ms\n",
      "Speed: 1.1ms preprocess, 356.0ms inference, 0.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 434.1ms\n",
      "Speed: 1.4ms preprocess, 434.1ms inference, 0.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 365.4ms\n",
      "Speed: 1.3ms preprocess, 365.4ms inference, 0.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 342.1ms\n",
      "Speed: 2.3ms preprocess, 342.1ms inference, 0.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 378.3ms\n",
      "Speed: 1.3ms preprocess, 378.3ms inference, 0.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 335.9ms\n",
      "Speed: 1.6ms preprocess, 335.9ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 362.1ms\n",
      "Speed: 1.3ms preprocess, 362.1ms inference, 0.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 333.0ms\n",
      "Speed: 1.2ms preprocess, 333.0ms inference, 0.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 340.1ms\n",
      "Speed: 1.4ms preprocess, 340.1ms inference, 0.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 340.0ms\n",
      "Speed: 1.4ms preprocess, 340.0ms inference, 0.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 327.2ms\n",
      "Speed: 1.4ms preprocess, 327.2ms inference, 0.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 368.1ms\n",
      "Speed: 1.3ms preprocess, 368.1ms inference, 0.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 331.4ms\n",
      "Speed: 1.4ms preprocess, 331.4ms inference, 0.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 357.9ms\n",
      "Speed: 1.2ms preprocess, 357.9ms inference, 0.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 365.7ms\n",
      "Speed: 1.9ms preprocess, 365.7ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 343.8ms\n",
      "Speed: 1.6ms preprocess, 343.8ms inference, 0.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 334.3ms\n",
      "Speed: 1.4ms preprocess, 334.3ms inference, 0.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 421.1ms\n",
      "Speed: 27.5ms preprocess, 421.1ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 372.0ms\n",
      "Speed: 1.2ms preprocess, 372.0ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 344.7ms\n",
      "Speed: 1.2ms preprocess, 344.7ms inference, 0.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 327.5ms\n",
      "Speed: 2.2ms preprocess, 327.5ms inference, 0.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 336.1ms\n",
      "Speed: 1.8ms preprocess, 336.1ms inference, 0.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 354.5ms\n",
      "Speed: 1.2ms preprocess, 354.5ms inference, 0.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 339.0ms\n",
      "Speed: 1.8ms preprocess, 339.0ms inference, 0.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 381.2ms\n",
      "Speed: 1.1ms preprocess, 381.2ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 355.2ms\n",
      "Speed: 1.4ms preprocess, 355.2ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 374.9ms\n",
      "Speed: 1.3ms preprocess, 374.9ms inference, 0.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 371.9ms\n",
      "Speed: 1.4ms preprocess, 371.9ms inference, 0.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 369.3ms\n",
      "Speed: 1.5ms preprocess, 369.3ms inference, 0.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 502.6ms\n",
      "Speed: 19.9ms preprocess, 502.6ms inference, 0.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 370.8ms\n",
      "Speed: 1.5ms preprocess, 370.8ms inference, 0.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 358.1ms\n",
      "Speed: 1.3ms preprocess, 358.1ms inference, 0.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 392.7ms\n",
      "Speed: 1.4ms preprocess, 392.7ms inference, 0.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 334.8ms\n",
      "Speed: 1.5ms preprocess, 334.8ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 361.0ms\n",
      "Speed: 1.4ms preprocess, 361.0ms inference, 0.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 339.6ms\n",
      "Speed: 1.4ms preprocess, 339.6ms inference, 0.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 343.0ms\n",
      "Speed: 1.3ms preprocess, 343.0ms inference, 0.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 354.7ms\n",
      "Speed: 1.7ms preprocess, 354.7ms inference, 0.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 343.1ms\n",
      "Speed: 1.7ms preprocess, 343.1ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 403.4ms\n",
      "Speed: 1.5ms preprocess, 403.4ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 1003.9ms\n",
      "Speed: 1.4ms preprocess, 1003.9ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 422.8ms\n",
      "Speed: 11.1ms preprocess, 422.8ms inference, 0.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 377.1ms\n",
      "Speed: 1.3ms preprocess, 377.1ms inference, 0.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 390.2ms\n",
      "Speed: 1.2ms preprocess, 390.2ms inference, 0.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 404.0ms\n",
      "Speed: 1.6ms preprocess, 404.0ms inference, 0.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 358.4ms\n",
      "Speed: 1.4ms preprocess, 358.4ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 357.9ms\n",
      "Speed: 1.4ms preprocess, 357.9ms inference, 0.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 360.1ms\n",
      "Speed: 1.9ms preprocess, 360.1ms inference, 0.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 394.9ms\n",
      "Speed: 1.2ms preprocess, 394.9ms inference, 0.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 390.7ms\n",
      "Speed: 1.2ms preprocess, 390.7ms inference, 0.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 370.8ms\n",
      "Speed: 1.4ms preprocess, 370.8ms inference, 0.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 355.2ms\n",
      "Speed: 1.5ms preprocess, 355.2ms inference, 0.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 338.0ms\n",
      "Speed: 1.9ms preprocess, 338.0ms inference, 0.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 362.9ms\n",
      "Speed: 1.1ms preprocess, 362.9ms inference, 0.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 356.7ms\n",
      "Speed: 1.4ms preprocess, 356.7ms inference, 0.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 353.2ms\n",
      "Speed: 1.1ms preprocess, 353.2ms inference, 0.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 419.7ms\n",
      "Speed: 1.2ms preprocess, 419.7ms inference, 0.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 365.1ms\n",
      "Speed: 2.1ms preprocess, 365.1ms inference, 0.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 362.9ms\n",
      "Speed: 1.4ms preprocess, 362.9ms inference, 0.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 334.7ms\n",
      "Speed: 1.3ms preprocess, 334.7ms inference, 0.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 347.7ms\n",
      "Speed: 4.3ms preprocess, 347.7ms inference, 0.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 349.0ms\n",
      "Speed: 12.7ms preprocess, 349.0ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 352.2ms\n",
      "Speed: 1.6ms preprocess, 352.2ms inference, 0.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 366.8ms\n",
      "Speed: 1.2ms preprocess, 366.8ms inference, 0.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 344.1ms\n",
      "Speed: 1.9ms preprocess, 344.1ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 351.8ms\n",
      "Speed: 1.9ms preprocess, 351.8ms inference, 0.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 361.4ms\n",
      "Speed: 1.3ms preprocess, 361.4ms inference, 0.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 339.4ms\n",
      "Speed: 1.8ms preprocess, 339.4ms inference, 0.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 349.6ms\n",
      "Speed: 1.7ms preprocess, 349.6ms inference, 0.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 497.5ms\n",
      "Speed: 39.9ms preprocess, 497.5ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 353.5ms\n",
      "Speed: 1.4ms preprocess, 353.5ms inference, 0.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 397.1ms\n",
      "Speed: 2.4ms preprocess, 397.1ms inference, 0.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 target, 349.5ms\n",
      "Speed: 1.4ms preprocess, 349.5ms inference, 4.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 target, 346.3ms\n",
      "Speed: 2.0ms preprocess, 346.3ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 target, 372.7ms\n",
      "Speed: 1.4ms preprocess, 372.7ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 target, 378.2ms\n",
      "Speed: 1.1ms preprocess, 378.2ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 target, 385.8ms\n",
      "Speed: 1.4ms preprocess, 385.8ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 targets, 342.5ms\n",
      "Speed: 1.3ms preprocess, 342.5ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 targets, 356.0ms\n",
      "Speed: 1.3ms preprocess, 356.0ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 persons, 1 backpack, 389.4ms\n",
      "Speed: 1.9ms preprocess, 389.4ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "1/1 [==============================] - 0s 106ms/step\n",
      "\n",
      "0: 384x640 2 persons, 2 backpacks, 382.1ms\n",
      "Speed: 1.5ms preprocess, 382.1ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "\n",
      "0: 384x640 (no detections), 351.6ms\n",
      "Speed: 1.1ms preprocess, 351.6ms inference, 0.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 342.0ms\n",
      "Speed: 1.4ms preprocess, 342.0ms inference, 0.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 407.7ms\n",
      "Speed: 3.4ms preprocess, 407.7ms inference, 0.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 332.8ms\n",
      "Speed: 1.4ms preprocess, 332.8ms inference, 0.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 372.6ms\n",
      "Speed: 1.3ms preprocess, 372.6ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 356.0ms\n",
      "Speed: 1.3ms preprocess, 356.0ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 351.2ms\n",
      "Speed: 1.4ms preprocess, 351.2ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 364.5ms\n",
      "Speed: 1.4ms preprocess, 364.5ms inference, 0.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 426.1ms\n",
      "Speed: 5.7ms preprocess, 426.1ms inference, 0.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 393.6ms\n",
      "Speed: 1.3ms preprocess, 393.6ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 target, 472.5ms\n",
      "Speed: 1.3ms preprocess, 472.5ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 348.7ms\n",
      "Speed: 1.4ms preprocess, 348.7ms inference, 0.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 377.9ms\n",
      "Speed: 1.4ms preprocess, 377.9ms inference, 0.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 target, 344.9ms\n",
      "Speed: 1.6ms preprocess, 344.9ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 target, 355.9ms\n",
      "Speed: 1.8ms preprocess, 355.9ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 352x640 3 persons, 1 backpack, 340.7ms\n",
      "Speed: 2.0ms preprocess, 340.7ms inference, 0.5ms postprocess per image at shape (1, 3, 352, 640)\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "\n",
      "0: 384x640 1 target, 383.0ms\n",
      "Speed: 1.5ms preprocess, 383.0ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 380.5ms\n",
      "Speed: 1.4ms preprocess, 380.5ms inference, 0.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 353.7ms\n",
      "Speed: 1.1ms preprocess, 353.7ms inference, 0.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 336.9ms\n",
      "Speed: 1.3ms preprocess, 336.9ms inference, 0.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 369.0ms\n",
      "Speed: 1.3ms preprocess, 369.0ms inference, 0.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 348.6ms\n",
      "Speed: 1.7ms preprocess, 348.6ms inference, 0.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 403.8ms\n",
      "Speed: 1.1ms preprocess, 403.8ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 target, 380.8ms\n",
      "Speed: 1.2ms preprocess, 380.8ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 383.6ms\n",
      "Speed: 1.4ms preprocess, 383.6ms inference, 0.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 target, 371.5ms\n",
      "Speed: 1.4ms preprocess, 371.5ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 target, 338.3ms\n",
      "Speed: 1.5ms preprocess, 338.3ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 target, 455.9ms\n",
      "Speed: 1.3ms preprocess, 455.9ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 378.9ms\n",
      "Speed: 1.9ms preprocess, 378.9ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 396.6ms\n",
      "Speed: 1.3ms preprocess, 396.6ms inference, 0.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 354.5ms\n",
      "Speed: 1.1ms preprocess, 354.5ms inference, 0.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 target, 362.7ms\n",
      "Speed: 1.2ms preprocess, 362.7ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 380.2ms\n",
      "Speed: 1.3ms preprocess, 380.2ms inference, 0.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 target, 358.0ms\n",
      "Speed: 3.8ms preprocess, 358.0ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 358.5ms\n",
      "Speed: 1.2ms preprocess, 358.5ms inference, 0.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 394.0ms\n",
      "Speed: 1.2ms preprocess, 394.0ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 348.1ms\n",
      "Speed: 1.3ms preprocess, 348.1ms inference, 0.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 346.6ms\n",
      "Speed: 1.4ms preprocess, 346.6ms inference, 0.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 353.1ms\n",
      "Speed: 1.8ms preprocess, 353.1ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 target, 368.4ms\n",
      "Speed: 1.6ms preprocess, 368.4ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 target, 363.9ms\n",
      "Speed: 1.3ms preprocess, 363.9ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 440.6ms\n",
      "Speed: 1.1ms preprocess, 440.6ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 343.7ms\n",
      "Speed: 1.4ms preprocess, 343.7ms inference, 0.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 target, 410.5ms\n",
      "Speed: 1.3ms preprocess, 410.5ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 target, 397.6ms\n",
      "Speed: 1.2ms preprocess, 397.6ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 480.2ms\n",
      "Speed: 1.6ms preprocess, 480.2ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "\n",
      "0: 384x640 1 target, 367.1ms\n",
      "Speed: 2.1ms preprocess, 367.1ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 342.9ms\n",
      "Speed: 2.0ms preprocess, 342.9ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "\n",
      "0: 384x640 (no detections), 366.9ms\n",
      "Speed: 1.5ms preprocess, 366.9ms inference, 0.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 target, 362.2ms\n",
      "Speed: 1.3ms preprocess, 362.2ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 354.4ms\n",
      "Speed: 1.1ms preprocess, 354.4ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "\n",
      "0: 384x640 (no detections), 374.5ms\n",
      "Speed: 1.8ms preprocess, 374.5ms inference, 0.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 target, 474.9ms\n",
      "Speed: 1.2ms preprocess, 474.9ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 349.0ms\n",
      "Speed: 1.5ms preprocess, 349.0ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 target, 380.2ms\n",
      "Speed: 1.3ms preprocess, 380.2ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 targets, 353.3ms\n",
      "Speed: 1.5ms preprocess, 353.3ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 target, 367.3ms\n",
      "Speed: 1.3ms preprocess, 367.3ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 target, 351.4ms\n",
      "Speed: 1.6ms preprocess, 351.4ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 target, 372.4ms\n",
      "Speed: 1.5ms preprocess, 372.4ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 366.6ms\n",
      "Speed: 1.0ms preprocess, 366.6ms inference, 0.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 377.2ms\n",
      "Speed: 1.5ms preprocess, 377.2ms inference, 0.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 366.7ms\n",
      "Speed: 1.3ms preprocess, 366.7ms inference, 0.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 369.7ms\n",
      "Speed: 1.3ms preprocess, 369.7ms inference, 0.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 target, 337.8ms\n",
      "Speed: 2.2ms preprocess, 337.8ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 target, 348.2ms\n",
      "Speed: 1.3ms preprocess, 348.2ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 target, 372.9ms\n",
      "Speed: 1.1ms preprocess, 372.9ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 targets, 337.9ms\n",
      "Speed: 1.4ms preprocess, 337.9ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 target, 350.2ms\n",
      "Speed: 1.3ms preprocess, 350.2ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 6 persons, 349.4ms\n",
      "Speed: 1.4ms preprocess, 349.4ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "\n",
      "0: 384x640 2 targets, 337.0ms\n",
      "Speed: 1.2ms preprocess, 337.0ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 persons, 423.2ms\n",
      "Speed: 1.1ms preprocess, 423.2ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "\n",
      "0: 384x640 2 targets, 342.4ms\n",
      "Speed: 3.1ms preprocess, 342.4ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 5 persons, 367.1ms\n",
      "Speed: 1.3ms preprocess, 367.1ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "\n",
      "0: 384x640 (no detections), 374.2ms\n",
      "Speed: 1.2ms preprocess, 374.2ms inference, 0.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 364.1ms\n",
      "Speed: 1.2ms preprocess, 364.1ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 377.1ms\n",
      "Speed: 1.2ms preprocess, 377.1ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 364.2ms\n",
      "Speed: 1.6ms preprocess, 364.2ms inference, 0.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 333.0ms\n",
      "Speed: 1.6ms preprocess, 333.0ms inference, 0.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 347.2ms\n",
      "Speed: 20.1ms preprocess, 347.2ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 326.0ms\n",
      "Speed: 1.3ms preprocess, 326.0ms inference, 0.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 371.4ms\n",
      "Speed: 1.9ms preprocess, 371.4ms inference, 0.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 340.9ms\n",
      "Speed: 1.4ms preprocess, 340.9ms inference, 0.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 341.4ms\n",
      "Speed: 1.5ms preprocess, 341.4ms inference, 0.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 396.5ms\n",
      "Speed: 1.3ms preprocess, 396.5ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 target, 348.8ms\n",
      "Speed: 2.4ms preprocess, 348.8ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 target, 350.7ms\n",
      "Speed: 1.3ms preprocess, 350.7ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 target, 430.1ms\n",
      "Speed: 1.2ms preprocess, 430.1ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 target, 360.6ms\n",
      "Speed: 1.8ms preprocess, 360.6ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 target, 321.6ms\n",
      "Speed: 1.3ms preprocess, 321.6ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 targets, 336.4ms\n",
      "Speed: 1.2ms preprocess, 336.4ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 targets, 343.2ms\n",
      "Speed: 1.1ms preprocess, 343.2ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 5 persons, 1 fire hydrant, 394.7ms\n",
      "Speed: 1.4ms preprocess, 394.7ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "\n",
      "0: 384x640 1 target, 338.7ms\n",
      "Speed: 1.7ms preprocess, 338.7ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 5 persons, 1 backpack, 351.6ms\n",
      "Speed: 1.1ms preprocess, 351.6ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "\n",
      "0: 384x640 1 target, 343.4ms\n",
      "Speed: 1.7ms preprocess, 343.4ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 5 persons, 393.0ms\n",
      "Speed: 3.8ms preprocess, 393.0ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "\n",
      "0: 384x640 2 targets, 390.0ms\n",
      "Speed: 1.5ms preprocess, 390.0ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 targets, 387.1ms\n",
      "Speed: 1.7ms preprocess, 387.1ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 targets, 365.2ms\n",
      "Speed: 2.8ms preprocess, 365.2ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 target, 601.4ms\n",
      "Speed: 34.8ms preprocess, 601.4ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 target, 383.4ms\n",
      "Speed: 2.0ms preprocess, 383.4ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 target, 335.7ms\n",
      "Speed: 22.4ms preprocess, 335.7ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 target, 354.7ms\n",
      "Speed: 1.6ms preprocess, 354.7ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 target, 375.0ms\n",
      "Speed: 18.1ms preprocess, 375.0ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 target, 351.4ms\n",
      "Speed: 1.5ms preprocess, 351.4ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 persons, 1 truck, 1 backpack, 379.5ms\n",
      "Speed: 6.0ms preprocess, 379.5ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "\n",
      "0: 384x640 1 target, 388.9ms\n",
      "Speed: 1.0ms preprocess, 388.9ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 persons, 1 truck, 437.0ms\n",
      "Speed: 2.5ms preprocess, 437.0ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "\n",
      "0: 384x640 1 target, 1669.5ms\n",
      "Speed: 1.4ms preprocess, 1669.5ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 persons, 1 truck, 1 backpack, 479.1ms\n",
      "Speed: 2.6ms preprocess, 479.1ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "\n",
      "0: 384x640 1 target, 380.8ms\n",
      "Speed: 10.0ms preprocess, 380.8ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 target, 369.8ms\n",
      "Speed: 11.6ms preprocess, 369.8ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 target, 359.6ms\n",
      "Speed: 3.6ms preprocess, 359.6ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 target, 357.3ms\n",
      "Speed: 1.3ms preprocess, 357.3ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 348.2ms\n",
      "Speed: 1.1ms preprocess, 348.2ms inference, 0.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 325.3ms\n",
      "Speed: 3.3ms preprocess, 325.3ms inference, 0.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 337.2ms\n",
      "Speed: 1.4ms preprocess, 337.2ms inference, 0.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 343.0ms\n",
      "Speed: 2.2ms preprocess, 343.0ms inference, 0.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 386.2ms\n",
      "Speed: 1.7ms preprocess, 386.2ms inference, 0.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 408.3ms\n",
      "Speed: 1.8ms preprocess, 408.3ms inference, 0.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 403.3ms\n",
      "Speed: 1.4ms preprocess, 403.3ms inference, 0.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 362.4ms\n",
      "Speed: 1.2ms preprocess, 362.4ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 443.3ms\n",
      "Speed: 1.6ms preprocess, 443.3ms inference, 0.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 354.6ms\n",
      "Speed: 15.5ms preprocess, 354.6ms inference, 0.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 350.2ms\n",
      "Speed: 1.2ms preprocess, 350.2ms inference, 0.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 354.5ms\n",
      "Speed: 1.4ms preprocess, 354.5ms inference, 0.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 352.8ms\n",
      "Speed: 1.3ms preprocess, 352.8ms inference, 0.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 369.9ms\n",
      "Speed: 1.4ms preprocess, 369.9ms inference, 0.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 365.3ms\n",
      "Speed: 1.2ms preprocess, 365.3ms inference, 0.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 363.1ms\n",
      "Speed: 1.1ms preprocess, 363.1ms inference, 0.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 364.2ms\n",
      "Speed: 1.8ms preprocess, 364.2ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 358.5ms\n",
      "Speed: 1.3ms preprocess, 358.5ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 344.4ms\n",
      "Speed: 1.2ms preprocess, 344.4ms inference, 0.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 355.4ms\n",
      "Speed: 1.3ms preprocess, 355.4ms inference, 0.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 373.9ms\n",
      "Speed: 1.7ms preprocess, 373.9ms inference, 0.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 344.2ms\n",
      "Speed: 1.1ms preprocess, 344.2ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 337.2ms\n",
      "Speed: 1.1ms preprocess, 337.2ms inference, 0.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 342.0ms\n",
      "Speed: 1.3ms preprocess, 342.0ms inference, 0.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 360.7ms\n",
      "Speed: 2.2ms preprocess, 360.7ms inference, 0.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 353.8ms\n",
      "Speed: 1.3ms preprocess, 353.8ms inference, 0.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 447.0ms\n",
      "Speed: 1.3ms preprocess, 447.0ms inference, 0.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 352.6ms\n",
      "Speed: 1.2ms preprocess, 352.6ms inference, 0.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 339.4ms\n",
      "Speed: 1.3ms preprocess, 339.4ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 388.4ms\n",
      "Speed: 1.3ms preprocess, 388.4ms inference, 0.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 365.2ms\n",
      "Speed: 1.3ms preprocess, 365.2ms inference, 0.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 342.7ms\n",
      "Speed: 1.3ms preprocess, 342.7ms inference, 0.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 388.8ms\n",
      "Speed: 1.4ms preprocess, 388.8ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 334.9ms\n",
      "Speed: 1.6ms preprocess, 334.9ms inference, 0.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 target, 395.5ms\n",
      "Speed: 1.2ms preprocess, 395.5ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 350.1ms\n",
      "Speed: 1.7ms preprocess, 350.1ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 373.0ms\n",
      "Speed: 1.1ms preprocess, 373.0ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 362.6ms\n",
      "Speed: 1.5ms preprocess, 362.6ms inference, 0.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 343.2ms\n",
      "Speed: 1.6ms preprocess, 343.2ms inference, 0.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 359.4ms\n",
      "Speed: 1.0ms preprocess, 359.4ms inference, 0.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 384.8ms\n",
      "Speed: 1.4ms preprocess, 384.8ms inference, 0.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 354.0ms\n",
      "Speed: 1.1ms preprocess, 354.0ms inference, 0.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 354.3ms\n",
      "Speed: 1.2ms preprocess, 354.3ms inference, 0.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 343.7ms\n",
      "Speed: 1.7ms preprocess, 343.7ms inference, 0.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 389.9ms\n",
      "Speed: 1.8ms preprocess, 389.9ms inference, 0.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 421.6ms\n",
      "Speed: 1.3ms preprocess, 421.6ms inference, 0.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 344.9ms\n",
      "Speed: 1.3ms preprocess, 344.9ms inference, 0.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 416.3ms\n",
      "Speed: 20.7ms preprocess, 416.3ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 349.3ms\n",
      "Speed: 1.5ms preprocess, 349.3ms inference, 0.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 353.7ms\n",
      "Speed: 1.2ms preprocess, 353.7ms inference, 0.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 422.9ms\n",
      "Speed: 1.6ms preprocess, 422.9ms inference, 0.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 356.3ms\n",
      "Speed: 1.6ms preprocess, 356.3ms inference, 0.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 385.4ms\n",
      "Speed: 1.2ms preprocess, 385.4ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 343.4ms\n",
      "Speed: 1.1ms preprocess, 343.4ms inference, 0.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 384.8ms\n",
      "Speed: 1.4ms preprocess, 384.8ms inference, 0.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 target, 405.6ms\n",
      "Speed: 1.4ms preprocess, 405.6ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 343.8ms\n",
      "Speed: 1.5ms preprocess, 343.8ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 365.5ms\n",
      "Speed: 1.3ms preprocess, 365.5ms inference, 0.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 target, 373.1ms\n",
      "Speed: 1.1ms preprocess, 373.1ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 target, 343.7ms\n",
      "Speed: 5.2ms preprocess, 343.7ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 345.2ms\n",
      "Speed: 23.2ms preprocess, 345.2ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 381.7ms\n",
      "Speed: 10.5ms preprocess, 381.7ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 target, 392.9ms\n",
      "Speed: 1.1ms preprocess, 392.9ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 target, 355.1ms\n",
      "Speed: 1.6ms preprocess, 355.1ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 target, 487.5ms\n",
      "Speed: 1.2ms preprocess, 487.5ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 target, 338.7ms\n",
      "Speed: 1.3ms preprocess, 338.7ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 target, 354.6ms\n",
      "Speed: 23.5ms preprocess, 354.6ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 target, 371.2ms\n",
      "Speed: 1.3ms preprocess, 371.2ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 target, 369.9ms\n",
      "Speed: 1.1ms preprocess, 369.9ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 target, 397.9ms\n",
      "Speed: 1.3ms preprocess, 397.9ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 target, 427.2ms\n",
      "Speed: 1.2ms preprocess, 427.2ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 target, 394.3ms\n",
      "Speed: 1.1ms preprocess, 394.3ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 target, 872.7ms\n",
      "Speed: 1.5ms preprocess, 872.7ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 target, 851.5ms\n",
      "Speed: 3.0ms preprocess, 851.5ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 target, 323.4ms\n",
      "Speed: 1.4ms preprocess, 323.4ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 target, 376.5ms\n",
      "Speed: 1.6ms preprocess, 376.5ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 416.1ms\n",
      "Speed: 1.3ms preprocess, 416.1ms inference, 0.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 target, 634.4ms\n",
      "Speed: 1.7ms preprocess, 634.4ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 target, 364.7ms\n",
      "Speed: 2.5ms preprocess, 364.7ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 386.4ms\n",
      "Speed: 1.6ms preprocess, 386.4ms inference, 0.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 target, 370.3ms\n",
      "Speed: 25.2ms preprocess, 370.3ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 target, 351.9ms\n",
      "Speed: 1.2ms preprocess, 351.9ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 target, 407.7ms\n",
      "Speed: 1.4ms preprocess, 407.7ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 target, 348.2ms\n",
      "Speed: 1.8ms preprocess, 348.2ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 target, 456.8ms\n",
      "Speed: 1.1ms preprocess, 456.8ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 target, 567.3ms\n",
      "Speed: 27.9ms preprocess, 567.3ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 target, 471.3ms\n",
      "Speed: 1.6ms preprocess, 471.3ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 394.0ms\n",
      "Speed: 2.5ms preprocess, 394.0ms inference, 0.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 target, 367.8ms\n",
      "Speed: 1.4ms preprocess, 367.8ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 target, 367.3ms\n",
      "Speed: 1.7ms preprocess, 367.3ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 target, 384.0ms\n",
      "Speed: 1.4ms preprocess, 384.0ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 343.2ms\n",
      "Speed: 1.3ms preprocess, 343.2ms inference, 0.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 350.9ms\n",
      "Speed: 1.2ms preprocess, 350.9ms inference, 0.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 379.9ms\n",
      "Speed: 1.2ms preprocess, 379.9ms inference, 0.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 952.0ms\n",
      "Speed: 1.2ms preprocess, 952.0ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 440.8ms\n",
      "Speed: 1.7ms preprocess, 440.8ms inference, 0.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 352.9ms\n",
      "Speed: 1.8ms preprocess, 352.9ms inference, 0.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 341.9ms\n",
      "Speed: 3.4ms preprocess, 341.9ms inference, 0.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 346.3ms\n",
      "Speed: 1.5ms preprocess, 346.3ms inference, 0.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 371.8ms\n",
      "Speed: 1.1ms preprocess, 371.8ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 385.2ms\n",
      "Speed: 1.1ms preprocess, 385.2ms inference, 0.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 378.5ms\n",
      "Speed: 1.3ms preprocess, 378.5ms inference, 0.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 355.0ms\n",
      "Speed: 1.3ms preprocess, 355.0ms inference, 0.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 440.7ms\n",
      "Speed: 3.8ms preprocess, 440.7ms inference, 0.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 363.4ms\n",
      "Speed: 1.5ms preprocess, 363.4ms inference, 0.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 363.0ms\n",
      "Speed: 1.5ms preprocess, 363.0ms inference, 0.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 350.9ms\n",
      "Speed: 1.6ms preprocess, 350.9ms inference, 0.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 370.1ms\n",
      "Speed: 1.8ms preprocess, 370.1ms inference, 0.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 327.4ms\n",
      "Speed: 11.9ms preprocess, 327.4ms inference, 0.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 565.1ms\n",
      "Speed: 2.1ms preprocess, 565.1ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 502.7ms\n",
      "Speed: 26.2ms preprocess, 502.7ms inference, 0.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 382.8ms\n",
      "Speed: 6.4ms preprocess, 382.8ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 395.3ms\n",
      "Speed: 1.0ms preprocess, 395.3ms inference, 0.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 417.2ms\n",
      "Speed: 1.7ms preprocess, 417.2ms inference, 0.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 564.4ms\n",
      "Speed: 1.2ms preprocess, 564.4ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 345.3ms\n",
      "Speed: 1.7ms preprocess, 345.3ms inference, 0.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 361.7ms\n",
      "Speed: 12.7ms preprocess, 361.7ms inference, 0.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 344.0ms\n",
      "Speed: 2.7ms preprocess, 344.0ms inference, 0.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 342.2ms\n",
      "Speed: 1.2ms preprocess, 342.2ms inference, 0.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 407.2ms\n",
      "Speed: 1.2ms preprocess, 407.2ms inference, 0.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 429.5ms\n",
      "Speed: 1.2ms preprocess, 429.5ms inference, 0.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 415.8ms\n",
      "Speed: 1.2ms preprocess, 415.8ms inference, 0.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 368.1ms\n",
      "Speed: 1.2ms preprocess, 368.1ms inference, 0.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 387.2ms\n",
      "Speed: 1.5ms preprocess, 387.2ms inference, 0.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 414.2ms\n",
      "Speed: 1.3ms preprocess, 414.2ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 439.1ms\n",
      "Speed: 1.3ms preprocess, 439.1ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 372.8ms\n",
      "Speed: 7.6ms preprocess, 372.8ms inference, 0.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 473.6ms\n",
      "Speed: 2.1ms preprocess, 473.6ms inference, 0.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 381.0ms\n",
      "Speed: 1.1ms preprocess, 381.0ms inference, 0.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 364.2ms\n",
      "Speed: 1.3ms preprocess, 364.2ms inference, 0.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 target, 356.0ms\n",
      "Speed: 1.1ms preprocess, 356.0ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 target, 365.0ms\n",
      "Speed: 1.1ms preprocess, 365.0ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 288x640 5 persons, 1 baseball bat, 336.4ms\n",
      "Speed: 1.1ms preprocess, 336.4ms inference, 1.1ms postprocess per image at shape (1, 3, 288, 640)\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "\n",
      "0: 384x640 1 target, 368.9ms\n",
      "Speed: 1.6ms preprocess, 368.9ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 1440.4ms\n",
      "Speed: 1.5ms preprocess, 1440.4ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 516.0ms\n",
      "Speed: 4.5ms preprocess, 516.0ms inference, 0.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 383.1ms\n",
      "Speed: 2.1ms preprocess, 383.1ms inference, 0.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 454.3ms\n",
      "Speed: 1.4ms preprocess, 454.3ms inference, 0.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 target, 352.2ms\n",
      "Speed: 1.6ms preprocess, 352.2ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 target, 425.9ms\n",
      "Speed: 1.6ms preprocess, 425.9ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 366.3ms\n",
      "Speed: 1.2ms preprocess, 366.3ms inference, 0.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 target, 363.8ms\n",
      "Speed: 1.4ms preprocess, 363.8ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 target, 548.5ms\n",
      "Speed: 10.0ms preprocess, 548.5ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 343.9ms\n",
      "Speed: 1.4ms preprocess, 343.9ms inference, 0.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 target, 391.3ms\n",
      "Speed: 1.3ms preprocess, 391.3ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 target, 352.0ms\n",
      "Speed: 1.3ms preprocess, 352.0ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 target, 336.7ms\n",
      "Speed: 1.9ms preprocess, 336.7ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 359.0ms\n",
      "Speed: 1.7ms preprocess, 359.0ms inference, 0.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 357.3ms\n",
      "Speed: 1.3ms preprocess, 357.3ms inference, 0.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 486.1ms\n",
      "Speed: 2.4ms preprocess, 486.1ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 494.7ms\n",
      "Speed: 1.5ms preprocess, 494.7ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 481.9ms\n",
      "Speed: 1.6ms preprocess, 481.9ms inference, 0.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 510.3ms\n",
      "Speed: 1.8ms preprocess, 510.3ms inference, 0.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 target, 353.6ms\n",
      "Speed: 1.3ms preprocess, 353.6ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 target, 372.4ms\n",
      "Speed: 1.8ms preprocess, 372.4ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 target, 355.2ms\n",
      "Speed: 1.6ms preprocess, 355.2ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 target, 396.7ms\n",
      "Speed: 1.3ms preprocess, 396.7ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 target, 372.8ms\n",
      "Speed: 1.7ms preprocess, 372.8ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 target, 368.6ms\n",
      "Speed: 1.2ms preprocess, 368.6ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 6 persons, 1 skis, 414.4ms\n",
      "Speed: 1.4ms preprocess, 414.4ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "\n",
      "0: 384x640 1 target, 369.1ms\n",
      "Speed: 1.3ms preprocess, 369.1ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 7 persons, 1 airplane, 1 skis, 353.8ms\n",
      "Speed: 1.3ms preprocess, 353.8ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "\n",
      "0: 384x640 1 target, 358.1ms\n",
      "Speed: 1.2ms preprocess, 358.1ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 7 persons, 1 airplane, 1 skis, 350.7ms\n",
      "Speed: 1.6ms preprocess, 350.7ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "\n",
      "0: 384x640 1 target, 357.0ms\n",
      "Speed: 1.7ms preprocess, 357.0ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 target, 714.6ms\n",
      "Speed: 45.7ms preprocess, 714.6ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 target, 796.4ms\n",
      "Speed: 1.7ms preprocess, 796.4ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 7 persons, 837.1ms\n",
      "Speed: 1.7ms preprocess, 837.1ms inference, 2.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "\n",
      "0: 384x640 1 target, 756.6ms\n",
      "Speed: 1.9ms preprocess, 756.6ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 7 persons, 548.3ms\n",
      "Speed: 2.0ms preprocess, 548.3ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "\n",
      "0: 384x640 1 target, 349.2ms\n",
      "Speed: 1.2ms preprocess, 349.2ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 6 persons, 386.9ms\n",
      "Speed: 1.7ms preprocess, 386.9ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "\n",
      "0: 384x640 1 target, 647.6ms\n",
      "Speed: 2.2ms preprocess, 647.6ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 6 persons, 597.9ms\n",
      "Speed: 8.5ms preprocess, 597.9ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "\n",
      "0: 384x640 2 targets, 605.7ms\n",
      "Speed: 5.9ms preprocess, 605.7ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 7 persons, 473.2ms\n",
      "Speed: 3.0ms preprocess, 473.2ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "\n",
      "0: 384x640 2 targets, 566.3ms\n",
      "Speed: 1.5ms preprocess, 566.3ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 8 persons, 575.0ms\n",
      "Speed: 1.7ms preprocess, 575.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "\n",
      "0: 384x640 2 targets, 397.0ms\n",
      "Speed: 1.4ms preprocess, 397.0ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 7 persons, 460.9ms\n",
      "Speed: 20.3ms preprocess, 460.9ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "\n",
      "0: 544x640 5 persons, 1 truck, 663.6ms\n",
      "Speed: 18.7ms preprocess, 663.6ms inference, 1.5ms postprocess per image at shape (1, 3, 544, 640)\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "\n",
      "0: 384x640 2 targets, 431.7ms\n",
      "Speed: 4.9ms preprocess, 431.7ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 7 persons, 415.8ms\n",
      "Speed: 1.5ms preprocess, 415.8ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "\n",
      "0: 384x640 2 targets, 505.8ms\n",
      "Speed: 5.4ms preprocess, 505.8ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 7 persons, 591.3ms\n",
      "Speed: 2.1ms preprocess, 591.3ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "\n",
      "0: 384x640 1 target, 483.8ms\n",
      "Speed: 1.7ms preprocess, 483.8ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 target, 572.0ms\n",
      "Speed: 2.2ms preprocess, 572.0ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 7 persons, 441.0ms\n",
      "Speed: 1.4ms preprocess, 441.0ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "\n",
      "0: 384x640 1 target, 390.3ms\n",
      "Speed: 1.7ms preprocess, 390.3ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 7 persons, 1 airplane, 454.0ms\n",
      "Speed: 2.6ms preprocess, 454.0ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "\n",
      "0: 384x640 1 target, 445.5ms\n",
      "Speed: 2.2ms preprocess, 445.5ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 7 persons, 1 airplane, 732.0ms\n",
      "Speed: 1.6ms preprocess, 732.0ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "\n",
      "0: 384x640 1 target, 794.2ms\n",
      "Speed: 19.2ms preprocess, 794.2ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 7 persons, 1 airplane, 1 skis, 481.6ms\n",
      "Speed: 2.5ms preprocess, 481.6ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "\n",
      "0: 384x640 1 target, 583.0ms\n",
      "Speed: 20.3ms preprocess, 583.0ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 7 persons, 1 skis, 3914.4ms\n",
      "Speed: 2.1ms preprocess, 3914.4ms inference, 63.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "\n",
      "0: 384x640 1 target, 4744.5ms\n",
      "Speed: 43.4ms preprocess, 4744.5ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 7 persons, 1 skis, 850.9ms\n",
      "Speed: 5.2ms preprocess, 850.9ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "\n",
      "0: 384x640 1 target, 1160.4ms\n",
      "Speed: 9.8ms preprocess, 1160.4ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 7 persons, 2 skiss, 1 snowboard, 647.3ms\n",
      "Speed: 2.8ms preprocess, 647.3ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "\n",
      "0: 384x640 1 target, 656.0ms\n",
      "Speed: 1.3ms preprocess, 656.0ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 7 persons, 1 skis, 456.9ms\n",
      "Speed: 1.6ms preprocess, 456.9ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "\n",
      "0: 384x640 1 target, 377.1ms\n",
      "Speed: 1.6ms preprocess, 377.1ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 8 persons, 363.7ms\n",
      "Speed: 2.3ms preprocess, 363.7ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "\n",
      "0: 384x640 1 target, 459.0ms\n",
      "Speed: 1.4ms preprocess, 459.0ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 7 persons, 468.7ms\n",
      "Speed: 1.7ms preprocess, 468.7ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "\n",
      "0: 384x640 1 target, 687.5ms\n",
      "Speed: 31.2ms preprocess, 687.5ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/Users/maxkucher/pytorch/howitzer-detector/detector.ipynb Cell 4\u001b[0m line \u001b[0;36m4\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/maxkucher/pytorch/howitzer-detector/detector.ipynb#W3sZmlsZQ%3D%3D?line=40'>41</a>\u001b[0m new_y2 \u001b[39m=\u001b[39m \u001b[39mmin\u001b[39m(frame\u001b[39m.\u001b[39mshape[\u001b[39m0\u001b[39m], y2 \u001b[39m+\u001b[39m (y2 \u001b[39m-\u001b[39m y1) \u001b[39m/\u001b[39m\u001b[39m/\u001b[39m \u001b[39m0.5\u001b[39m)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/maxkucher/pytorch/howitzer-detector/detector.ipynb#W3sZmlsZQ%3D%3D?line=41'>42</a>\u001b[0m cropped_frames \u001b[39m=\u001b[39m frame[\u001b[39mint\u001b[39m(new_y1):\u001b[39mint\u001b[39m(new_y2), \u001b[39mint\u001b[39m(new_x1):\u001b[39mint\u001b[39m(new_x2)]\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/maxkucher/pytorch/howitzer-detector/detector.ipynb#W3sZmlsZQ%3D%3D?line=44'>45</a>\u001b[0m new_results \u001b[39m=\u001b[39m yolo_model(cropped_frames)[\u001b[39m0\u001b[39m]\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/maxkucher/pytorch/howitzer-detector/detector.ipynb#W3sZmlsZQ%3D%3D?line=46'>47</a>\u001b[0m \u001b[39mfor\u001b[39;00m new_result \u001b[39min\u001b[39;00m new_results\u001b[39m.\u001b[39mboxes\u001b[39m.\u001b[39mdata\u001b[39m.\u001b[39mtolist():\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/maxkucher/pytorch/howitzer-detector/detector.ipynb#W3sZmlsZQ%3D%3D?line=47'>48</a>\u001b[0m     x_11, y_11, x_22, y_22, new_score, new_class_id \u001b[39m=\u001b[39m new_result\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/ultralytics/engine/model.py:169\u001b[0m, in \u001b[0;36mModel.__call__\u001b[0;34m(self, source, stream, **kwargs)\u001b[0m\n\u001b[1;32m    146\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__call__\u001b[39m(\n\u001b[1;32m    147\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[1;32m    148\u001b[0m     source: Union[\u001b[39mstr\u001b[39m, Path, \u001b[39mint\u001b[39m, \u001b[39mlist\u001b[39m, \u001b[39mtuple\u001b[39m, np\u001b[39m.\u001b[39mndarray, torch\u001b[39m.\u001b[39mTensor] \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m,\n\u001b[1;32m    149\u001b[0m     stream: \u001b[39mbool\u001b[39m \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m,\n\u001b[1;32m    150\u001b[0m     \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs,\n\u001b[1;32m    151\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m \u001b[39mlist\u001b[39m:\n\u001b[1;32m    152\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    153\u001b[0m \u001b[39m    An alias for the predict method, enabling the model instance to be callable.\u001b[39;00m\n\u001b[1;32m    154\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    167\u001b[0m \u001b[39m        (List[ultralytics.engine.results.Results]): A list of prediction results, encapsulated in the Results class.\u001b[39;00m\n\u001b[1;32m    168\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 169\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mpredict(source, stream, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/ultralytics/engine/model.py:429\u001b[0m, in \u001b[0;36mModel.predict\u001b[0;34m(self, source, stream, predictor, **kwargs)\u001b[0m\n\u001b[1;32m    427\u001b[0m \u001b[39mif\u001b[39;00m prompts \u001b[39mand\u001b[39;00m \u001b[39mhasattr\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpredictor, \u001b[39m\"\u001b[39m\u001b[39mset_prompts\u001b[39m\u001b[39m\"\u001b[39m):  \u001b[39m# for SAM-type models\u001b[39;00m\n\u001b[1;32m    428\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpredictor\u001b[39m.\u001b[39mset_prompts(prompts)\n\u001b[0;32m--> 429\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpredictor\u001b[39m.\u001b[39mpredict_cli(source\u001b[39m=\u001b[39msource) \u001b[39mif\u001b[39;00m is_cli \u001b[39melse\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mpredictor(source\u001b[39m=\u001b[39;49msource, stream\u001b[39m=\u001b[39;49mstream)\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/ultralytics/engine/predictor.py:204\u001b[0m, in \u001b[0;36mBasePredictor.__call__\u001b[0;34m(self, source, model, stream, *args, **kwargs)\u001b[0m\n\u001b[1;32m    202\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstream_inference(source, model, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[1;32m    203\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 204\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mlist\u001b[39;49m(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mstream_inference(source, model, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs))\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/torch/utils/_contextlib.py:35\u001b[0m, in \u001b[0;36m_wrap_generator.<locals>.generator_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m     33\u001b[0m     \u001b[39m# Issuing `None` to a generator fires it up\u001b[39;00m\n\u001b[1;32m     34\u001b[0m     \u001b[39mwith\u001b[39;00m ctx_factory():\n\u001b[0;32m---> 35\u001b[0m         response \u001b[39m=\u001b[39m gen\u001b[39m.\u001b[39;49msend(\u001b[39mNone\u001b[39;49;00m)\n\u001b[1;32m     37\u001b[0m     \u001b[39mwhile\u001b[39;00m \u001b[39mTrue\u001b[39;00m:\n\u001b[1;32m     38\u001b[0m         \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m     39\u001b[0m             \u001b[39m# Forward the response to our caller and get its next request\u001b[39;00m\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/ultralytics/engine/predictor.py:283\u001b[0m, in \u001b[0;36mBasePredictor.stream_inference\u001b[0;34m(self, source, model, *args, **kwargs)\u001b[0m\n\u001b[1;32m    281\u001b[0m \u001b[39m# Inference\u001b[39;00m\n\u001b[1;32m    282\u001b[0m \u001b[39mwith\u001b[39;00m profilers[\u001b[39m1\u001b[39m]:\n\u001b[0;32m--> 283\u001b[0m     preds \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49minference(im, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    284\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39margs\u001b[39m.\u001b[39membed:\n\u001b[1;32m    285\u001b[0m         \u001b[39myield from\u001b[39;00m [preds] \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(preds, torch\u001b[39m.\u001b[39mTensor) \u001b[39melse\u001b[39;00m preds  \u001b[39m# yield embedding tensors\u001b[39;00m\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/ultralytics/engine/predictor.py:140\u001b[0m, in \u001b[0;36mBasePredictor.inference\u001b[0;34m(self, im, *args, **kwargs)\u001b[0m\n\u001b[1;32m    134\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"Runs inference on a given image using the specified model and arguments.\"\"\"\u001b[39;00m\n\u001b[1;32m    135\u001b[0m visualize \u001b[39m=\u001b[39m (\n\u001b[1;32m    136\u001b[0m     increment_path(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39msave_dir \u001b[39m/\u001b[39m Path(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbatch[\u001b[39m0\u001b[39m][\u001b[39m0\u001b[39m])\u001b[39m.\u001b[39mstem, mkdir\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n\u001b[1;32m    137\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39margs\u001b[39m.\u001b[39mvisualize \u001b[39mand\u001b[39;00m (\u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39msource_type\u001b[39m.\u001b[39mtensor)\n\u001b[1;32m    138\u001b[0m     \u001b[39melse\u001b[39;00m \u001b[39mFalse\u001b[39;00m\n\u001b[1;32m    139\u001b[0m )\n\u001b[0;32m--> 140\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmodel(im, augment\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49margs\u001b[39m.\u001b[39;49maugment, visualize\u001b[39m=\u001b[39;49mvisualize, embed\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49margs\u001b[39m.\u001b[39;49membed, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/torch/nn/modules/module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_compiled_call_impl(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)  \u001b[39m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1510\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m-> 1511\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call_impl(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/torch/nn/modules/module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1515\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1516\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1518\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1519\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1522\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m   1523\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/ultralytics/nn/autobackend.py:384\u001b[0m, in \u001b[0;36mAutoBackend.forward\u001b[0;34m(self, im, augment, visualize, embed)\u001b[0m\n\u001b[1;32m    381\u001b[0m     im \u001b[39m=\u001b[39m im\u001b[39m.\u001b[39mpermute(\u001b[39m0\u001b[39m, \u001b[39m2\u001b[39m, \u001b[39m3\u001b[39m, \u001b[39m1\u001b[39m)  \u001b[39m# torch BCHW to numpy BHWC shape(1,320,192,3)\u001b[39;00m\n\u001b[1;32m    383\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpt \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnn_module:  \u001b[39m# PyTorch\u001b[39;00m\n\u001b[0;32m--> 384\u001b[0m     y \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmodel(im, augment\u001b[39m=\u001b[39;49maugment, visualize\u001b[39m=\u001b[39;49mvisualize, embed\u001b[39m=\u001b[39;49membed)\n\u001b[1;32m    385\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mjit:  \u001b[39m# TorchScript\u001b[39;00m\n\u001b[1;32m    386\u001b[0m     y \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmodel(im)\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/torch/nn/modules/module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_compiled_call_impl(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)  \u001b[39m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1510\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m-> 1511\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call_impl(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/torch/nn/modules/module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1515\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1516\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1518\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1519\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1522\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m   1523\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/ultralytics/nn/tasks.py:83\u001b[0m, in \u001b[0;36mBaseModel.forward\u001b[0;34m(self, x, *args, **kwargs)\u001b[0m\n\u001b[1;32m     81\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(x, \u001b[39mdict\u001b[39m):  \u001b[39m# for cases of training and validating while training.\u001b[39;00m\n\u001b[1;32m     82\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mloss(x, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m---> 83\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mpredict(x, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/ultralytics/nn/tasks.py:101\u001b[0m, in \u001b[0;36mBaseModel.predict\u001b[0;34m(self, x, profile, visualize, augment, embed)\u001b[0m\n\u001b[1;32m     99\u001b[0m \u001b[39mif\u001b[39;00m augment:\n\u001b[1;32m    100\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_predict_augment(x)\n\u001b[0;32m--> 101\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_predict_once(x, profile, visualize, embed)\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/ultralytics/nn/tasks.py:122\u001b[0m, in \u001b[0;36mBaseModel._predict_once\u001b[0;34m(self, x, profile, visualize, embed)\u001b[0m\n\u001b[1;32m    120\u001b[0m \u001b[39mif\u001b[39;00m profile:\n\u001b[1;32m    121\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_profile_one_layer(m, x, dt)\n\u001b[0;32m--> 122\u001b[0m x \u001b[39m=\u001b[39m m(x)  \u001b[39m# run\u001b[39;00m\n\u001b[1;32m    123\u001b[0m y\u001b[39m.\u001b[39mappend(x \u001b[39mif\u001b[39;00m m\u001b[39m.\u001b[39mi \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39msave \u001b[39melse\u001b[39;00m \u001b[39mNone\u001b[39;00m)  \u001b[39m# save output\u001b[39;00m\n\u001b[1;32m    124\u001b[0m \u001b[39mif\u001b[39;00m visualize:\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/torch/nn/modules/module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_compiled_call_impl(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)  \u001b[39m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1510\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m-> 1511\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call_impl(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/torch/nn/modules/module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1515\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1516\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1518\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1519\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1522\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m   1523\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/ultralytics/nn/modules/block.py:225\u001b[0m, in \u001b[0;36mC2f.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    223\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"Forward pass through C2f layer.\"\"\"\u001b[39;00m\n\u001b[1;32m    224\u001b[0m y \u001b[39m=\u001b[39m \u001b[39mlist\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcv1(x)\u001b[39m.\u001b[39mchunk(\u001b[39m2\u001b[39m, \u001b[39m1\u001b[39m))\n\u001b[0;32m--> 225\u001b[0m y\u001b[39m.\u001b[39;49mextend(m(y[\u001b[39m-\u001b[39;49m\u001b[39m1\u001b[39;49m]) \u001b[39mfor\u001b[39;49;00m m \u001b[39min\u001b[39;49;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mm)\n\u001b[1;32m    226\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcv2(torch\u001b[39m.\u001b[39mcat(y, \u001b[39m1\u001b[39m))\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/ultralytics/nn/modules/block.py:225\u001b[0m, in \u001b[0;36m<genexpr>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    223\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"Forward pass through C2f layer.\"\"\"\u001b[39;00m\n\u001b[1;32m    224\u001b[0m y \u001b[39m=\u001b[39m \u001b[39mlist\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcv1(x)\u001b[39m.\u001b[39mchunk(\u001b[39m2\u001b[39m, \u001b[39m1\u001b[39m))\n\u001b[0;32m--> 225\u001b[0m y\u001b[39m.\u001b[39mextend(m(y[\u001b[39m-\u001b[39;49m\u001b[39m1\u001b[39;49m]) \u001b[39mfor\u001b[39;00m m \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mm)\n\u001b[1;32m    226\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcv2(torch\u001b[39m.\u001b[39mcat(y, \u001b[39m1\u001b[39m))\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/torch/nn/modules/module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_compiled_call_impl(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)  \u001b[39m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1510\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m-> 1511\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call_impl(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/torch/nn/modules/module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1515\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1516\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1518\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1519\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1522\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m   1523\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/ultralytics/nn/modules/block.py:335\u001b[0m, in \u001b[0;36mBottleneck.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    333\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, x):\n\u001b[1;32m    334\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"'forward()' applies the YOLO FPN to input data.\"\"\"\u001b[39;00m\n\u001b[0;32m--> 335\u001b[0m     \u001b[39mreturn\u001b[39;00m x \u001b[39m+\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcv2(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcv1(x)) \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39madd \u001b[39melse\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcv2(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcv1(x))\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/torch/nn/modules/module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_compiled_call_impl(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)  \u001b[39m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1510\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m-> 1511\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call_impl(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/torch/nn/modules/module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1515\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1516\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1518\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1519\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1522\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m   1523\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/ultralytics/nn/modules/conv.py:54\u001b[0m, in \u001b[0;36mConv.forward_fuse\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     52\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward_fuse\u001b[39m(\u001b[39mself\u001b[39m, x):\n\u001b[1;32m     53\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Perform transposed convolution of 2D data.\"\"\"\u001b[39;00m\n\u001b[0;32m---> 54\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mact(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mconv(x))\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/torch/nn/modules/module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_compiled_call_impl(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)  \u001b[39m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1510\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m-> 1511\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call_impl(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/torch/nn/modules/module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1515\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1516\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1518\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1519\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1522\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m   1523\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/torch/nn/modules/conv.py:460\u001b[0m, in \u001b[0;36mConv2d.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    459\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39minput\u001b[39m: Tensor) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tensor:\n\u001b[0;32m--> 460\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_conv_forward(\u001b[39minput\u001b[39;49m, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mweight, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbias)\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/torch/nn/modules/conv.py:456\u001b[0m, in \u001b[0;36mConv2d._conv_forward\u001b[0;34m(self, input, weight, bias)\u001b[0m\n\u001b[1;32m    452\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpadding_mode \u001b[39m!=\u001b[39m \u001b[39m'\u001b[39m\u001b[39mzeros\u001b[39m\u001b[39m'\u001b[39m:\n\u001b[1;32m    453\u001b[0m     \u001b[39mreturn\u001b[39;00m F\u001b[39m.\u001b[39mconv2d(F\u001b[39m.\u001b[39mpad(\u001b[39minput\u001b[39m, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_reversed_padding_repeated_twice, mode\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpadding_mode),\n\u001b[1;32m    454\u001b[0m                     weight, bias, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstride,\n\u001b[1;32m    455\u001b[0m                     _pair(\u001b[39m0\u001b[39m), \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdilation, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mgroups)\n\u001b[0;32m--> 456\u001b[0m \u001b[39mreturn\u001b[39;00m F\u001b[39m.\u001b[39;49mconv2d(\u001b[39minput\u001b[39;49m, weight, bias, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mstride,\n\u001b[1;32m    457\u001b[0m                 \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mpadding, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdilation, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mgroups)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "cap = cv2.VideoCapture(\"/Users/maxkucher/pytorch/howitzer-detector/video_1.mp4\")\n",
    "model = YOLO(\"/Users/maxkucher/pytorch/howitzer-detector/best.pt\")\n",
    "yolo_model = YOLO(\"yolov8l\")\n",
    "\n",
    "\n",
    "names = model.names\n",
    "yolo_names = yolo_model.names\n",
    "threshold = 0.5\n",
    "\n",
    "while True:\n",
    "\n",
    "    total_objects = 0\n",
    "    howitzers = 0\n",
    "    decoys = 0\n",
    "    unkowns = 0\n",
    "\n",
    "    person_value = 0\n",
    "    car_value = 0\n",
    "    bus_value = 0\n",
    "    truck_value = 0\n",
    "\n",
    "\n",
    "    ret, frame = cap.read()\n",
    "    results = model(frame)[0]\n",
    "\n",
    "    for result in results.boxes.data.tolist():\n",
    "        x1, y1, x2, y2, score, class_id = result\n",
    "\n",
    "        x_center = int((x1 + x2) / 2)\n",
    "        y_center = int((y1 + y2) / 2)\n",
    "\n",
    "        \n",
    "\n",
    "        if score > threshold:\n",
    "            total_objects += 1\n",
    "\n",
    "            new_x1 = max(0, x1 - (x2 - x1) // 0.5)\n",
    "            new_y1 = max(0, y1 - (y2 - y1) // 0.5)\n",
    "            new_x2 = min(frame.shape[1], x2 + (x2 - x1) // 0.5)\n",
    "            new_y2 = min(frame.shape[0], y2 + (y2 - y1) // 0.5)\n",
    "            cropped_frames = frame[int(new_y1):int(new_y2), int(new_x1):int(new_x2)]\n",
    "\n",
    "\n",
    "            new_results = yolo_model(cropped_frames)[0]\n",
    "\n",
    "            for new_result in new_results.boxes.data.tolist():\n",
    "                x_11, y_11, x_22, y_22, new_score, new_class_id = new_result\n",
    "                class_name = yolo_names[int(new_class_id)]\n",
    "\n",
    "                new_x_center = ((x_11 + x_22) / 2)\n",
    "                new_y_center = ((y_11 + y_22) / 2)\n",
    "\n",
    "                obj_color = (255, 0, 0)\n",
    "\n",
    "                if new_score > threshold and class_name in [\"person\", \"car\", \"bus\", \"truck\"]:\n",
    "                    cv2.rectangle(frame, (int(x_11), int(y_11)), (int(x_22), int(y_22)), obj_color, 2)\n",
    "                    cv2.putText(frame, class_name.upper(), (int(x_11), int(y_11 - 10)), cv2.FONT_HERSHEY_SIMPLEX, 1.3, obj_color, 3, cv2.LINE_AA)\n",
    "\n",
    "\n",
    "                    if class_name == \"person\":\n",
    "                        person_value = 1\n",
    "                    else:\n",
    "                        person_value = 0\n",
    "\n",
    "                    \n",
    "                    if class_name == \"car\":\n",
    "                        car_value = 1\n",
    "                    else:\n",
    "                        car_value = 0\n",
    "\n",
    "                    \n",
    "                    if class_name == \"bus\":\n",
    "                        bus_value = 1\n",
    "                    else:\n",
    "                        bus_value = 0\n",
    "\n",
    "                    \n",
    "                    if class_name == \"truck\":\n",
    "                        truck_value = 1\n",
    "                    else:\n",
    "                        truck_value = 0\n",
    "\n",
    "\n",
    "                \n",
    "\n",
    "            pred = np.argmax(analyzer_model.predict(np.array([[person_value, car_value, bus_value, truck_value]])))\n",
    "            pred_list = [\"Decoy\", \"Howitzer\", \"Undecided\"]\n",
    "            text = pred_list[int(pred)]\n",
    "                \n",
    "            if text == \"Decoy\":\n",
    "                color = (0, 255, 0)\n",
    "                decoys += 1\n",
    "            elif text == \"Howitzer\":\n",
    "                color =  (0, 0, 255)\n",
    "                howitzers += 1\n",
    "            elif text == \"Undecided\":\n",
    "                color =  (0, 255, 255)\n",
    "                unkowns += 1\n",
    "                        \n",
    "            cv2.rectangle(frame, (int(x1), int(y1)), (int(x2), int(y2)), color, 2)\n",
    "            cv2.circle(frame, (x_center, y_center), 5, color, thickness=cv2.FILLED)\n",
    "            cv2.putText(frame, f\"Target status: {text.upper()}\", (int(x1), int(y1 - 30)), cv2.FONT_HERSHEY_SIMPLEX, 1.3, color, 3, cv2.LINE_AA)\n",
    "\n",
    "        \n",
    "    cv2.rectangle(frame, (8, 15), (350, 25),  (255, 255, 255), 20)\n",
    "    cv2.putText(frame, f\"Total object count: {total_objects}\", (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 0, 0), 2)\n",
    "\n",
    "    cv2.rectangle(frame, (8, 55), (350, 65),  (255, 255, 255), 20)\n",
    "    cv2.putText(frame, f\"Real howitzers: {howitzers}\", (10, 70), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 0, 0), 2)\n",
    "\n",
    "    cv2.rectangle(frame, (8, 95), (350, 105),  (255, 255, 255), 20)\n",
    "    cv2.putText(frame, f\"Undecided targets: {unkowns}\", (10, 110), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 0, 0), 2)\n",
    "        \n",
    "    cv2.rectangle(frame, (8, 135), (350, 145),  (255, 255, 255), 20)\n",
    "    cv2.putText(frame, f\"Decoys: {decoys}\", (10, 150), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 0, 0), 2)\n",
    "\n",
    "\n",
    "                    \n",
    "    if not ret:\n",
    "        break\n",
    "    \n",
    "    # даем имя рамке и выводим ее \n",
    "    cv2.imshow(\"Object Detection\", frame)\n",
    "    \n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
